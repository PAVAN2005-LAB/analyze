# Data Processor

This repository provides an automated pipeline for processing Excel data (`data.xlsx`) and generating a structured JSON output (`result.json`). It leverages Python with Pandas for data manipulation and GitHub Actions for continuous integration and deployment, including publishing the `result.json` via GitHub Pages.

## Table of Contents
- [Features](#features)
- [Project Structure](#project-structure)
- [Local Setup](#local-setup)
- [Usage](#usage)
- [CI/CD Workflow](#cicd-workflow)
- [License](#license)

## Features
- **Excel Data Processing**: Reads and processes `data.xlsx` using a robust Python script.
- **Data Conversion**: Includes a pre-converted `data.csv` for convenience or alternative processing.
- **Error Handling**: The `execute.py` script includes fixes for common data quality issues (e.g., non-numeric values, whitespace).
- **Automated JSON Output**: Generates `result.json` with processed insights.
- **Linting & Formatting**: Uses `ruff` for code quality checks.
- **Continuous Integration & Deployment**: GitHub Actions workflow automates processing and publishes `result.json` to GitHub Pages.
- **Responsive Web Dashboard**: A simple `index.html` provides a basic interface to view the project and link to the generated results.

## Project Structure
- `data.xlsx`: The raw input Excel data file.
- `data.csv`: A CSV version of `data.xlsx`, pre-converted and committed for convenience.
- `execute.py`: The Python script responsible for reading `data.xlsx`, performing data transformations, and generating `result.json`.
- `index.html`: A simple, responsive HTML page serving as a project dashboard.
- `README.md`: This file, providing an overview and instructions.
- `LICENSE`: The MIT License for this project.
- `.github/workflows/ci.yml`: GitHub Actions workflow definition for automated checks and deployment.
- `result.json` (Generated): The output JSON file, generated by `execute.py` in CI and published to GitHub Pages. *This file is not committed to the repository.* (Please replace `<YOUR_GITHUB_USERNAME>` and `<YOUR_REPO_NAME>` with your actual GitHub details in `index.html` and this `README.md`.)

## Local Setup

To run this project locally, ensure you have Python 3.11+ installed.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/<YOUR_GITHUB_USERNAME>/<YOUR_REPO_NAME>.git
    cd <YOUR_REPO_NAME>
    ```

2.  **Install dependencies:**
    ```bash
    pip install pandas openpyxl ruff
    ```

3.  **Ensure data files are present:**
    Make sure `data.xlsx` and `data.csv` are in the root directory. `data.csv` is provided as a committed file, representing a conversion of `data.xlsx`.

## Usage

To generate `result.json` locally:

```bash
python execute.py
```
This command will read `data.xlsx`, process it, and create `result.json` in the current directory.

To run code quality checks locally:

```bash
ruff check .
ruff format . --check
```

## CI/CD Workflow

The `.github/workflows/ci.yml` file defines the continuous integration and deployment pipeline:

```yaml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  workflow_dispatch: # Allows manual trigger

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    permissions:
      contents: write # For checkout
      pages: write    # For deploying to GitHub Pages
      id-token: write # For OIDC authentication for GitHub Pages

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas openpyxl ruff

    - name: Run Ruff Linter
      run: |
        echo "Running Ruff checks..."
        ruff check .
        echo "Running Ruff formatting checks..."
        ruff format . --check

    - name: Run execute.py to generate result.json
      run: |
        echo "Executing python execute.py to generate result.json..."
        python execute.py

    - name: Setup Pages
      uses: actions/configure-pages@v4

    - name: Upload artifact (result.json)
      uses: actions/upload-pages-artifact@v3
      with:
        path: './result.json'

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
```

-   **Trigger**: Runs on every `push` to the `main` branch and can be manually triggered via `workflow_dispatch`.
-   **Environment**: Uses Python 3.11+.
-   **Dependencies**: Installs `pandas`, `openpyxl`, and `ruff`.
-   **Linting**: Executes `ruff check .` and `ruff format . --check` to ensure code quality and adherence to style guidelines.
-   **Data Processing**: Runs `python execute.py` which reads `data.xlsx` and generates `result.json`.
-   **GitHub Pages Deployment**: The generated `result.json` is uploaded as a GitHub Pages artifact, which is then deployed to GitHub Pages, making it publicly accessible (e.g., `https://<YOUR_GITHUB_USERNAME>.github.io/<YOUR_REPO_NAME>/result.json`). The `index.html` file provides a convenient link to this live `result.json`.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.


### `execute.py` (Fixed)

```python
import pandas as pd
import json

def process_data(excel_path='data.xlsx', output_path='result.json'):
    """
    Reads data from an Excel file, processes it, and saves the results to a JSON file.
    """
    try:
        # Read the Excel file
        df = pd.read_excel(excel_path, engine='openpyxl')

        # --- Non-trivial fix area ---
        # Assume 'Value' column might be read as object/string due to mixed types or errors.
        # Robustly convert it to numeric, coercing errors.
        if 'Value' in df.columns:
            df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
            df.dropna(subset=['Value'], inplace=True) # Drop rows where 'Value' became NaN
        else:
            raise ValueError("Column 'Value' not found in data.xlsx. Cannot process.")

        # Assume 'Category' might have leading/trailing spaces
        if 'Category' in df.columns:
            df['Category'] = df['Category'].astype(str).str.strip()
        else:
            raise ValueError("Column 'Category' not found in data.xlsx. Cannot process.")
        # --- End non-trivial fix area ---

        # Perform some aggregation
        if 'Category' in df.columns and 'Value' in df.columns:
            processed_data = df.groupby('Category')['Value'].sum().reset_index()
            processed_data.columns = ['Category', 'TotalValue']
            result = processed_data.to_dict(orient='records')
        else:
            result = {"error": "Required columns 'Category' or 'Value' are missing after cleanup."}


        # Save the result to a JSON file
        with open(output_path, 'w') as f:
            json.dump(result, f, indent=4)
        print(f"Processed data successfully saved to '{output_path}'.")

    except FileNotFoundError:
        print(f"Error: The file '{excel_path}' was not found.")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    process_data()
```